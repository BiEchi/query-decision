{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/may_conversation_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8276/4129446421.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conversations.dropna(subset=['user_prompt', 'bot_response'], inplace=True)\n",
      "/tmp/ipykernel_8276/4129446421.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conversations['user_prompt'] = conversations['user_prompt'].apply(lambda x: \"user: \" + str(x))\n",
      "/tmp/ipykernel_8276/4129446421.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conversations['bot_response'] = conversations['bot_response'].apply(lambda x: \"bot: \" + str(x))\n",
      "/tmp/ipykernel_8276/4129446421.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conversations['turn'] = conversations['user_prompt'] + '\\n' + conversations['bot_response']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user: can we talk\\nbot: What other sports simu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: can we talk\\nbot: What other sports simu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user: can we talk\\nbot: What other sports simu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user: can we talk\\nbot: What other sports simu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user: can we talk\\nbot: What other sports simu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16673</th>\n",
       "      <td>user: let's chat\\nbot: I don't feel comfortabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16674</th>\n",
       "      <td>user: let's chat\\nbot: I don't feel comfortabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16675</th>\n",
       "      <td>user: let's chat\\nbot: I don't feel comfortabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16676</th>\n",
       "      <td>user: how do you do things on your own without...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16677</th>\n",
       "      <td>user: how do you do things on your own without...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16678 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  dialog\n",
       "0      user: can we talk\\nbot: What other sports simu...\n",
       "1      user: can we talk\\nbot: What other sports simu...\n",
       "2      user: can we talk\\nbot: What other sports simu...\n",
       "3      user: can we talk\\nbot: What other sports simu...\n",
       "4      user: can we talk\\nbot: What other sports simu...\n",
       "...                                                  ...\n",
       "16673  user: let's chat\\nbot: I don't feel comfortabl...\n",
       "16674  user: let's chat\\nbot: I don't feel comfortabl...\n",
       "16675  user: let's chat\\nbot: I don't feel comfortabl...\n",
       "16676  user: how do you do things on your own without...\n",
       "16677  user: how do you do things on your own without...\n",
       "\n",
       "[16678 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations = data[['user_prompt', 'bot_response', 'conversation_id']]\n",
    "# dropna user_prompt\n",
    "conversations.dropna(subset=['user_prompt', 'bot_response'], inplace=True)\n",
    "# group using conversation_id, turn to list: [\"user:\", user_prompt1, \"bot\", bot_response1, \"user:\", user_prompt2, \"bot\", bot_response2, ...]\n",
    "conversations['user_prompt'] = conversations['user_prompt'].apply(lambda x: \"user: \" + str(x))\n",
    "conversations['bot_response'] = conversations['bot_response'].apply(lambda x: \"bot: \" + str(x))\n",
    "conversations['turn'] = conversations['user_prompt'] + '\\n' + conversations['bot_response']\n",
    "conversations = conversations.groupby('conversation_id')['turn'].apply(list)\n",
    "conversations = conversations.reset_index()\n",
    "\n",
    "# only reserve conversations with more than 2 turns\n",
    "conversations = conversations[conversations['turn'].apply(lambda x: len(x) > 2)]\n",
    "# all turns after the second turn constructs a conversation, e.g., if the conversation has [1, 2, 3, 4], then we have two conversations: [1, 2, 3] and [1, 2, 3, 4]\n",
    "turn_wise_conversations = []\n",
    "for i in range(len(conversations)):\n",
    "    for j in range(2, len(conversations.iloc[i]['turn'])):\n",
    "        turn_wise_conversation = conversations.iloc[i]['turn'][:j]\n",
    "        turn_wise_conversations.append(\"\\n\".join(turn_wise_conversation))\n",
    "\n",
    "df = pd.DataFrame(turn_wise_conversations, columns=['dialog'])\n",
    "\n",
    "# the dialog should end with user utterance, so we should delete the last bot utterance\n",
    "df['dialog'] = df['dialog'].apply(lambda x: x.split('\\n')[:-1])\n",
    "df['dialog'] = df['dialog'].apply(lambda x: \"\\n\".join(x))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: cards\n",
      "bot: I haven't seen The Flash yet, but it sounds like an exciting action-packed movie; have you watched it and what did you think of it?\n",
      "user: cards\n",
      "bot: I haven't seen The Flash yet, but it sounds like an exciting action-packed movie; have you watched it and what did you think of it?\n",
      "user: sp on\n",
      "bot: The Flash is an action-packed TV show featuring Grant Gustin, Candice Patton, and Danielle Panabaker, where Barry Allen gains the power of super speed after being struck by lightning and fights crime in Central City, rated TV-PG with a 7.5 out of 10 IMDb r\n",
      "user: sp on\n",
      "bot: The Flash is an action-packed TV show featuring Grant Gustin, Candice Patton, and Danielle Panabaker, where Barry Allen gains the power of super speed after being struck by lightning and fights crime in Central City, rated TV-PG with a 7.5 out of 10 IMDb r\n",
      "user: i wanna learn about f. b. i.\n",
      "bot: That's okay, as they say, 'You can't judge a book by its cover', so let me ask you this: Have you ever been interested in exploring the world around us through our senses?\n",
      "user: i wanna learn about f. b. i.\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[11]['dialog'])\n",
    "df.to_json('data/may_conversation_data_processed.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"model/train_on_maybe_valid/\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"model/train_on_maybe_valid/\")\n",
    "model.to('cuda')\n",
    "PREFIX = \"Does the context require to search something on the Internet: \"\n",
    "POSTFIX = \" __is-search-required__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Hello, welcome to Alexa social bot. What do you want to chat?\n",
      "what is the weather like by you?\n",
      "Its raining here :( so im indoors playing board games, what about you?\n",
      "what games are you playing\n",
      "Im a big fan of chess and i sometimes play checkers, do you play a lot of board games?\n",
      "not a lot, but i do play checkers.  since you like chess have you watched the queens gamit on netflix?\n",
      "How much do you play? and I havent watched it yet, do you know if its any good?\n",
      "i just started watching, it is phenomenal, and i dont know anything about chess\n",
      "Ill definitely check it out then! Have you ever played much chess?\n",
      "get me more info\n",
      "Output: ['__do-search__']\n",
      "Do not search prob: 0.0658704861998558\n",
      "Do search prob: 0.9341146945953369\n",
      "=============\n",
      "Input: Hello, welcome to Alexa social bot. What do you want to chat?\n",
      "Hoodies are my favorite type of clothing; I like how versatile they are.\n",
      "I agree! my favorite brand of hoodies is the North Face Gordon Lyons Hoodie; this is currently on clearance sale at Macys \n",
      "Oh wow, really? I should totally go to Macy's and get one!\n",
      "Good for you; you can get it online also with free shipping\n",
      "That's awesome. Did you already get one? \n",
      "Output: ['__do-search__']\n",
      "Do not search prob: 0.2659548819065094\n",
      "Do search prob: 0.7339948415756226\n",
      "=============\n",
      "Input: Hello, welcome to Alexa social bot. What do you want to chat?\n",
      "I went to the card shop today and picked up a pack of baseball cards. I ended up getting a rare Ken Griffey Jr! I can't wait to get a nice protective sleeve for it.\n",
      "There are many rare Ken Griffey Jr cards one of the most rare would be  the 1989 Bowman Tiffany cards that were of a rare set of special factory print that only printed 6000 cards\n",
      "Wow! It would be quite something for me to own that card one day. It would be a prized possession to me. Do you watch baseball?\n",
      "I do not watch baseball. Although baseball is really good for cardiovascular training. \n",
      "That's too bad, I think baseball is fascinating with all its statistics. Do you train for anything in particular, a marathon perhaps?\n",
      "I do not train for anything specific, I just feel that one should be healthy on the inside. \n",
      "That's a good point. It's important to keep the mind and body sharp, but eating healthy is paramount too. What are you doing tonight? \n",
      "Output: ['__do-not-search__']\n",
      "Do not search prob: 0.5979187488555908\n",
      "Do search prob: 0.4020101726055145\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "def predict(input_id, decoder_input, model):\n",
    "    next_token_logits = model(input_ids=input_id, decoder_input_ids=decoder_input)[0]\n",
    "    # use softmax and get the probability of token 2264 (not) and 13173 (search)\n",
    "    do_not_search_prob = torch.softmax(next_token_logits[0, -1, :], dim=0)[2264].item()\n",
    "    do_search_prob = torch.softmax(next_token_logits[0, -1, :], dim=0)[13173].item()\n",
    "    output = model.generate(input_id, max_length=50)\n",
    "    # print(torch.cuda.memory_allocated())\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True), do_not_search_prob, do_search_prob\n",
    "\n",
    "decoder_input = torch.tensor([0, 3, 834, 834, 26, 32, 18]).unsqueeze(0).to('cuda')\n",
    "\n",
    "flattened_convos = [\n",
    "    \"\"\"bot:Hello, welcome to Alexa social bot. What do you want to chat? user:what is the weather like by you? bot:Its raining here :( so im indoors playing board games, what about you? user:what games are you playing bot:Im a big fan of chess and i sometimes play checkers, do you play a lot of board games? user:not a lot, but i do play checkers.  since you like chess have you watched the queens gamit on netflix? bot:How much do you play? and I havent watched it yet, do you know if its any good? user:i just started watching, it is phenomenal, and i dont know anything about chess bot:Ill definitely check it out then! Have you ever played much chess? user:get me more info\"\"\",\n",
    "    \"\"\"bot:Hello, welcome to Alexa social bot. What do you want to chat? user:Hoodies are my favorite type of clothing; I like how versatile they are. bot:I agree! my favorite brand of hoodies is the North Face Gordon Lyons Hoodie; this is currently on clearance sale at Macys  user:Oh wow, really? I should totally go to Macy's and get one! bot:Good for you; you can get it online also with free shipping user:would you  \"\"\",\n",
    "    \"\"\"bot:Hello, welcome to Alexa social bot. What do you want to chat? user:I went to the card shop today and picked up a pack of baseball cards. I ended up getting a rare Ken Griffey Jr! I can't wait to get a nice protective sleeve for it. bot:There are many rare Ken Griffey Jr cards one of the most rare would be  the 1989 Bowman Tiffany cards that were of a rare set of special factory print that only printed 6000 cards user:Wow! It would be quite something for me to own that card one day. It would be a prized possession to me. Do you watch baseball? bot:I do not watch baseball. Although baseball is really good for cardiovascular training.  user:That's too bad, I think baseball is fascinating with all its statistics. Do you train for anything in particular, a marathon perhaps? bot:I do not train for anything specific, I just feel that one should be healthy on the inside.  user:That's a good point. It's important to keep the mind and body sharp, but eating healthy is paramount too. What are you doing tonight? \"\"\"\n",
    "]\n",
    "\n",
    "for flattened_convo in flattened_convos:\n",
    "    flattened_convo = flattened_convo.replace(\" user:\", \"\\n\").replace(\" bot:\", \"\\n\").replace(\"bot:\", \"\")\n",
    "    print(\"Input:\", flattened_convo)\n",
    "    input_id = tokenizer(PREFIX + flattened_convo, return_tensors='pt').input_ids.to('cuda')\n",
    "    outputs = predict(input_id, decoder_input, model)\n",
    "    print(\"Output:\", outputs[0])\n",
    "    print(\"Do not search prob:\", outputs[1])\n",
    "    print(\"Do search prob:\", outputs[2])\n",
    "    print(\"=============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16678/16678 [00:08<00:00, 2076.84it/s]\n",
      "  0%|          | 0/16678 [00:00<?, ?it/s]/tmp/ipykernel_3106/4080988466.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['do_search_prob'].iloc[i] = outputs[2]\n",
      "  1%|          | 101/16678 [00:22<1:02:18,  4.43it/s]"
     ]
    }
   ],
   "source": [
    "df['flattened'] = df['dialog'].apply(lambda x: x.replace(\"user:\", \"\").replace(\"bot:\", \"\"))\n",
    "# reserve only the last 3 turns ([-7:])\n",
    "df['reserved'] = df['flattened'].apply(lambda x: '\\n'.join(x.split('\\n')[-7:]))\n",
    "reserved = df['reserved'].tolist()\n",
    "\n",
    "print(\"tokenizing...\")\n",
    "input_ids = []\n",
    "for i in tqdm(range(len(reserved))):\n",
    "    input_ids.append(tokenizer.encode(PREFIX + reserved[i] + POSTFIX, return_tensors=\"pt\").to('cuda'))\n",
    "\n",
    "# create a column 'do_search_prob' to store the probability of searching\n",
    "print(\"predicting...\")\n",
    "df['do_search_prob'] = 0.0\n",
    "for i, input_id in enumerate(tqdm(input_ids)):\n",
    "    outputs = predict(input_id, decoder_input, model)\n",
    "    df['do_search_prob'].iloc[i] = outputs[2]\n",
    "\n",
    "# save the conversations\n",
    "df.to_json('data/may_conversation_data_processed_with_prob.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
